---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am a third year Ph.D. student at <a href="https://www.ntu.edu.sg/">Nanyang Technological University</a>, supervised by Prof. <a href="https://personal.ntu.edu.sg/shijian.lu/index.htm">Lu Shijian</a>. I received my B.S. degree from <a href="https://www.pku.edu.cn/">Peking University</a> in 2022, supervised by Prof. <a href="http://www.vie.group/ttj">Jiang Tingting</a>.

My research interests include computer vision and deep learning, especially in the fields of 3D/2D scene understanding.

<span class='anchor' id='news'></span>

# üî• News
- *2024.09*: One paper is accepted by <b>NeurIPS 2024!</b>
- *2024.02*: One paper is accepted by <b>CVPR 2024!</b>
- *2024.01*: One paper is accepted by <b>ICLR 2024!</b>
- *2023.07*: Two papers are accepted by <b>ICCV 2023!</b>

<span class='anchor' id='publications'></span>

# üìù Publications 

[//]: # (----------- Preprint 2024 -------------------------)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Preprint</div><img src='images/Preprint24_Multimodal.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Multimodal 3D Reasoning Segmentation with Complex Scenes](https://arxiv.org/abs/2411.13927)

[//]: # (<strong><span class='show_paper_citations' data='ElujT6oAAAAJ:hqOjcs7Dif8C'></span></strong>)

<u><b>Xueying Jiang</b></u>, Lewei Lu, Ling Shao, Shijian Lu

<i>Preprint, 2024</i>

<a href="https://arxiv.org/abs/2411.13927">paper</a> 
/ <a href="https://raw.githubusercontent.com/jiang-xueying/jiang-xueying.github.io/main/bibtex/jiang2024multimodal.html">bibtex</a>
/ <a href="">code</a>
/ <a href="">dataset</a>
/ <a href="https://jiang-xueying.github.io/projects/jiang2024multimodal/index">project page</a>

</div>
</div>

[//]: # (----------- NeurIPS 2024 -------------------------)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024</div><img src='images/NeurIPS24_Monomae.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[MonoMAE: Enhancing Monocular 3D Detection through Depth-Aware Masked Autoencoders](https://arxiv.org/pdf/2405.07696) 

[//]: # (<strong><span class='show_paper_citations' data='ElujT6oAAAAJ:hqOjcs7Dif8C'></span></strong>)

<u><b>Xueying Jiang</b></u>, Sheng Jin, Xiaoqin Zhang, Ling Shao, Shijian Lu

<i>NeurIPS, 2024</i>

<a href="https://arxiv.org/pdf/2405.07696">paper</a> 
/ <a href="https://raw.githubusercontent.com/jiang-xueying/jiang-xueying.github.io/main/bibtex/jiang2024monomae.html">bibtex</a>
/ <a href="https://jiang-xueying.github.io/projects/jiang2024monomae/index">project page</a>

</div>
</div>

[//]: # (----------- CVPR 2024 -------------------------)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/CVPR24_Weakly.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Weakly Supervised Monocular 3D Detection with a Single-View Image](https://arxiv.org/pdf/2402.19144v1.pdf) 

[//]: # (<strong><span class='show_paper_citations' data='ElujT6oAAAAJ:hqOjcs7Dif8C'></span></strong>)

<u><b>Xueying Jiang</b></u>, Sheng Jin, Lewei Lu, Xiaoqin Zhang, Shijian Lu

<i>CVPR, 2024</i>

<a href="https://arxiv.org/pdf/2402.19144v1.pdf">paper</a> 
/ <a href="https://raw.githubusercontent.com/jiang-xueying/jiang-xueying.github.io/main/bibtex/jiang2024weakly.html">bibtex</a>

</div>
</div>


[//]: # (----------- ICLR 2024 -------------------------)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2024</div><img src='images/ICLR24_LLMs.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[LLMs Meet VLMs: Boost Open Vocabulary Object Detection with Fine-grained Descriptors](https://arxiv.org/pdf/2402.04630.pdf) 

[//]: # (<strong><span class='show_paper_citations' data='ElujT6oAAAAJ:hqOjcs7Dif8C'></span></strong>)

Sheng Jin, <u><b>Xueying Jiang</b></u>, Jiaxing Huang, Lewei Lu, Shijian Lu


<i>ICLR, 2024</i>

<a href="https://arxiv.org/pdf/2402.04630.pdf">paper</a> 
/ <a href="https://raw.githubusercontent.com/jiang-xueying/jiang-xueying.github.io/main/bibtex/jin2024llms.html">bibtex</a>

</div>
</div>


[//]: # (----------- ICCV 2023 -------------------------)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2023</div><img src='images/ICCV23_Domain.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Domain Generalization via Balancing Training Difficulty and Model Capability](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Domain_Generalization_via_Balancing_Training_Difficulty_and_Model_Capability_ICCV_2023_paper.pdf) 

[//]: # (<strong><span class='show_paper_citations' data='ElujT6oAAAAJ:hqOjcs7Dif8C'></span></strong>)

<u><b>Xueying Jiang</b></u>, Jiaxing Huang, Sheng Jin, Shijian Lu

<i>ICCV, 2023</i>

<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Domain_Generalization_via_Balancing_Training_Difficulty_and_Model_Capability_ICCV_2023_paper.pdf">paper</a> 
/ <a href="https://raw.githubusercontent.com/jiang-xueying/jiang-xueying.github.io/main/bibtex/jiang2023domain.html">bibtex</a>

</div>
</div>


[//]: # (----------- ICCV 2023 -------------------------)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2023</div><img src='images/ICCV23_Black.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Black-box Unsupervised Domain Adaptation with Bi-directional Atkinson-Shiffrin Memory](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Black-Box_Unsupervised_Domain_Adaptation_with_Bi-Directional_Atkinson-Shiffrin_Memory_ICCV_2023_paper.pdf) 

[//]: # (<strong><span class='show_paper_citations' data='ElujT6oAAAAJ:hqOjcs7Dif8C'></span></strong>)

Jingyi Zhang, Jiaxing Huang, <u><b>Xueying Jiang</b></u>, Shijian Lu

<i>ICCV, 2023</i>

<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Black-Box_Unsupervised_Domain_Adaptation_with_Bi-Directional_Atkinson-Shiffrin_Memory_ICCV_2023_paper.pdf">paper</a> 
/ <a href="https://raw.githubusercontent.com/jiang-xueying/jiang-xueying.github.io/main/bibtex/zhang2023black.html">bibtex</a>

</div>
</div>



<span class='anchor' id='education'></span>

# üìñ Education
- *2022.08 - Present:* Doctor of Philosophy, S-Lab, College of Computing and Data Science, Nanyang Technological University
- *2018.09 - 2022.07:* Bachelor in Intelligence Science and Technology, School of Electronics Engineering and Computer Science, Peking University


<span class='anchor' id='service'></span>
# üíª Service
## Conference Reviewer
- CVPR, ICCV, ECCV, NeurIPS, ICML, ICLR, MM, ACCV


## Journal Reviewer
- IEEE TCSVT


<span class='anchor' id='teaching'></span>
# üë©‚Äçüè´ Teaching
- Teaching Assistant: SC2002/CE2002/CZ2002 Object Oriented Design & Programming, NTU, 2023 Spring, 2023 Fall



[//]: # (**Contact:** xueying003@e.ntu.edu.sg)

[//]: # (**Last Update:** May, 2024)

[//]: # (Thanks for the template of <a href="https://github.com/RayeRen/acad-homepage.github.io">Yi Ren</a>)


[//]: # (<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=UA1prgTfM8f4KdsTtZDKPAqAagf4Sr6L0d9xRVyOdrE&cl=ffffff&w=300"></script>)

<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=0BIYeBsibdR2LYwdkZWai6r2NccfTZ96HDqvr9WYt9s&co=9fc7e3&cmo=3acc3a&cmn=ff5353&ct=ffffff'></script>


[//]: # (<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=0BIYeBsibdR2LYwdkZWai6r2NccfTZ96HDqvr9WYt9s&cl=ffffff&w=a"></script>)