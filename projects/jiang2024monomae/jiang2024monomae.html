<!--或许回头换成这个更好看https://github.com/eliahuhorwitz/Academic-project-page-template-->
<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}

	h1 {
		font-size:32px;
		font-weight:300;
	}

	.disclaimerbox {
		background-color: #eee;
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}

	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}

	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}

	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
	<title>MonoMAE</title>
	<meta property="og:image" content="Path to my teaser.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="MonoMAE: Enhancing Monocular 3D Detection through Depth-Aware Masked Autoencoders" />
	<meta property="og:description" content="Paper description." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:30px"><b>[NeurIPS 2024] MonoMAE: Enhancing Monocular 3D Detection through Depth-Aware Masked Autoencoders</b></span>
		<table align=center width=600px>
			<table align=center width=600px>
				<tr>
					<td align=center width=100px>
						<center>
<!--							<span style="font-size:20px"><a href="https://jxy04250.github.io/">Xueying Jiang<sup>1</sup></a></span>-->
							<span style="font-size:20px">Xueying Jiang<sup>1</sup></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px">Sheng Jin<sup>1</sup></span>
						</center>
					</td>
			</table>
			<table align=center width=600px>
                    <td align=center width=100px>
						<center>
							<span style="font-size:20px">Xiaoqin Zhang<sup>2</sup></span>
						</center>
					</td>
                    <td align=center width=100px>
						<center>
							<span style="font-size:20px">Ling Shao<sup>3</sup></span>
						</center>
					</td>
                    <td align=center width=100px>
						<center>
							<span style="font-size:20px">Shijian Lu<sup>1*</sup></span>
						</center>
					</td>
				</tr>
			</table>
			<br>
			<table align=center width=800px>
				<td align=center width=600px>
					<span style="font-size:20px"><sup>1</sup>S-Lab, Nanyang Technological University, Singapore</span>
				</td>
			</table>
			<table align=center width=800px>
				<td align=center width=600px>
					<span style="font-size:20px"><sup>2</sup>College of Computer Science and Technology, Zhejiang University of Technology, China</span>
				</td>
			</table>
			<table align=center width=800px>
				<td align=center width=600px>
					<span style="font-size:20px"><sup>3</sup>UCAS-Terminus AI Lab, University of Chinese Academy of Sciences, China</span>
				</td>
			</table>
			<table>
				<td align=center width=300px>
					<span style="font-size:16px"><sup>*</sup>Corresponding author.</span>
				</td>
			</table>
			<table align=center width=250px>
				<tr>
					<td align=center width=120px>
						<center>
							<span style="font-size:20px"><a href='https://arxiv.org/pdf/2405.07696'>[arXiv]</a></span>
						</center>
					</td>
<!--					<td align=center width=120px>-->
<!--						<center>-->
<!--							<span style="font-size:20px"><a href='XX'>[code]</a></span><br>-->
<!--						</center>-->
<!--					</td>-->
				</tr>
			</table>
		</table>
	</center>

<!--	<table align=center width=850px>-->
<!--		<center><h1><span style="text-align: center;">Video</span></h1></center>-->
<!--		<tr>-->
<!--			<iframe width="100%" height="100%" class="elementor-video-iframe" src="https://www.youtube.com/embed/745tBSLk8PY?si=UbaSNRkC9xB0QCzr" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>-->
<!--			</iframe>-->
<!--		</tr>-->
<!--	</table>-->

	<hr>

	<table align=center width=850px>
		<center><h1><span style="font-size:24px">Abstract</span></h1></center>
		<tr>
			<td style="text-align: justify;">
				Monocular 3D object detection aims for precise 3D localization and identification of objects from a single-view image. Despite its recent progress, it often struggles while handling pervasive object occlusions that tend to complicate and degrade the prediction of object dimensions, depths, and orientations. We design MonoMAE, a monocular 3D detector inspired by Masked Autoencoders that addresses the object occlusion issue by masking and reconstructing objects in the feature space. MonoMAE consists of two novel designs. The first is depth-aware masking that selectively masks certain parts of non-occluded object queries in the feature space for simulating occluded object queries for network training. It masks non-occluded object queries by balancing the masked and preserved query portions adaptively according to the depth information. The second is lightweight query completion that works with the depth-aware masking to learn to reconstruct and complete the masked object queries. With the proposed feature-space occlusion and completion, MonoMAE learns enriched 3D representations that achieve superior monocular 3D detection performance qualitatively and quantitatively for both occluded and non-occluded objects. Additionally, MonoMAE learns generalizable representations that can work well in new domains.
			</td>
		</tr>
	</table>
	<br>

	<hr>

	<center>
		<table align="center" width="1000px">
			<center><h1><span style="font-size:24px">Method</span></h1></center>
			<tr>
				<td width="1000px">
					<center>
						<figure>
							<img class="round" style="width:800px" src="images/MonoMAE/overall_architecture.jpg" alt="Overall Framework of MonoMAE"/>
							<figcaption><span style="font-size:18px">Overall Framework of MonoMAE.</span></figcaption>
						</figure>
						<br>
						<figure>
							<img class="round" style="width:800px" src="images/MonoMAE/depth_aware_masking.jpg" alt="Illustration of the Depth-Aware Masking"/>
							<figcaption><span style="font-size:18px">Illustration of the Depth-Aware Masking.</span></figcaption>
						</figure>
					</center>
				</td>
			</tr>
		</table>

	<hr>

		<table align="center" width="1000px">
			<center><h1><span style="font-size:24px">Experiments</span></h1></center>
			<tr>
				<td width="1000px">
					<center>
						<figure>
							<img class="round" style="width:800px" src="images/MonoMAE/experimental_results.jpg" alt="Experimental Results"/>
							<figcaption><span style="font-size:18px">Benchmarking on the KITTI 3D test set.</span></figcaption>
						</figure>
					</center>
				</td>
			</tr>
		</table>

	<hr>

		<center><h1><span style="font-size:24px">Visual Results</span></h1></center>
		<figure>
  			<p><img src="images/MonoMAE/compare_with_sota.jpg" width="800" alt="Visualization">
  			<figcaption>
    			Detection visualization over the KITTI val set.
		    </figcaption>
		</figure>
	<hr>

	<table align="center" width="850px">
		<center><h1><span style="font-size:24px">Citation</span></h1></center>
		<tr>
			<td style="text-align: center;">
				<pre style="display: inline-block; text-align: left;">
	@article{jiang2024monomae,
		title={MonoMAE: Enhancing Monocular 3D Detection through Depth-Aware Masked Autoencoders},
		author={Jiang, Xueying and Jin, Sheng and Zhang, Xiaoqin and Shao, Ling and Lu, Shijian},
		journal=NeurIPS,
		year={2024}
	}
				</pre>
			</td>
		</tr>
	</table>
	<br>

<br>
</body>
</html>
